{
  "Architecture": [
    "any"
  ],
  "Binary": [
    "llama.cpp"
  ],
  "Build-Depends": [
    "cmake, debhelper-compat (= 13), libcurl4-openssl-dev, libggml-cpu, pkgconf"
  ],
  "Checksums-Sha256": [
    "d8789de2db0baefbac96fc39b599f119cb1f6309ac6e0014c9683d099bed130d 2010 llama.cpp_5760+dfsg-2.dsc 9970b00f8ab7b3ce0acbf890e1ba481059468a7353286a932023a22cbbec8c0a 4916412 llama.cpp_5760+dfsg.orig.tar.xz cdbac818ce4387dafda31c344476066e9b946e188f2e9f17415be2191109cbc2 9164 llama.cpp_5760+dfsg-2.debian.tar.xz"
  ],
  "Directory": [
    "pool/main/l/llama.cpp"
  ],
  "Files": [
    "acb9d709e96153496c1e51f850f7c51c 2010 llama.cpp_5760+dfsg-2.dsc 1f04ac7eb903fe174f84f2a02d4e5c57 4916412 llama.cpp_5760+dfsg.orig.tar.xz 216ebd379bd214a640c1767086ceff18 9164 llama.cpp_5760+dfsg-2.debian.tar.xz"
  ],
  "Format": [
    "3.0 (quilt)"
  ],
  "Homepage": [
    "https://github.com/ggml-org/llama.cpp/"
  ],
  "Maintainer": [
    "Debian Deep Learning Team \u003cdebian-ai@lists.debian.org\u003e"
  ],
  "Package": [
    "llama.cpp"
  ],
  "Package-List": [
    "llama.cpp deb science optional arch=any"
  ],
  "Priority": [
    "optional"
  ],
  "Section": [
    "misc"
  ],
  "Standards-Version": [
    "4.7.2"
  ],
  "Uploaders": [
    "Christian Kastner \u003cckk@debian.org\u003e"
  ],
  "Vcs-Browser": [
    "https://salsa.debian.org/deeplearning-team/llama.cpp"
  ],
  "Vcs-Git": [
    "https://salsa.debian.org/deeplearning-team/llama.cpp.git"
  ],
  "Version": [
    "5760+dfsg-2"
  ]
}